{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1）两种概率模型\n",
    "\n",
    "对于分类问题，不妨引入目标类别标记$y\\in \\mathbf{Y}=\\{c_1,\\dots,c_N\\}$。\n",
    "\n",
    "首先，根据我们熟悉的**贝叶斯定理**（也是**条件概率**的定义）以及**概率链式法则**，容易写出下面这个等式：\n",
    "\n",
    "$$\n",
    "\\dfrac{P(\\boldsymbol{x} \\ | \\ y)P(y)}{\\sum_{i=1}^N P(\\boldsymbol{x} \\ | \\ c_i)P(c_i)} = P(y \\ | \\ \\boldsymbol{x}) = \\dfrac{P(y \\ ,\\ \\boldsymbol{x})}{\\sum_{i=1}^N P(c_i\\ ,\\  \\boldsymbol{x})}\n",
    "$$\n",
    "\n",
    "$P(y\\ |\\ \\boldsymbol{x})$可以理解成**后验概率**，本质上是一种条件概率，特别之处是：根据特征变量（输入），给出目标变量（输出）的概率分布。\n",
    "\n",
    "$P(y)$可以理解成**先验概率**, 即我们预先已经知道目标变量的概率分布。\n",
    "\n",
    "$P(\\boldsymbol{x} \\ | \\ y)$可以理解成**拟然率**, 本质上也是一种条件概率， 特别之处是： 根据目标变量，给出特征变量的概率分布。\n",
    "\n",
    "$P(y \\ , \\ \\boldsymbol{x})$就是目标变量和特征变量之间的**联合概率分布**。\n",
    "\n",
    "于是，可以对**后验概率**进行两个方面解读：\n",
    "\n",
    "左边的等式可以理解成： **后验概率**就是**先验概率**乘上**拟然率**然后再**归一化**。 \n",
    "\n",
    "右边的等式则说明，通过**联合概率分布**可以直接生成**后验概率**。\n",
    "\n",
    "最后，可以获得两种建模方式：\n",
    "\n",
    "如果试图直接对**后验概率**建模， 则称之为**判别式模型**；如果试图直接对**联合概率分布**建模，则称之为**生成式模型**。\n",
    "\n",
    "无论是**判别式模型**还是**生成式模型**最终都要获得**后验概率分布**$P(y\\ |\\ \\boldsymbol{x})$，进而获得**贝叶斯最优分类器**：\n",
    "\n",
    "$$\n",
    "h^*(\\boldsymbol{x}) = \\underset{c \\in \\mathbf{Y}}{\\mathrm{argmax}} \\ P(c\\ |\\ \\boldsymbol{x})\n",
    "$$\n",
    "\n",
    "区别在于：**判别式模型**的结果就是后验概率分布，而**生成式模型**的结果是联合概率分布$P(y \\ ,\\ \\boldsymbol{x})$，需要据此求得后验概率分布：\n",
    "\n",
    "$$\n",
    "P(y \\ | \\ \\boldsymbol{x}) = \\dfrac{P(y \\ ,\\ \\boldsymbol{x})}{\\sum_{i=1}^N P(c_i\\ ,\\  \\boldsymbol{x})}\n",
    "$$\n",
    "\n",
    "由于分母部分$\\sum_{i=1}^N P(c_i\\ ,\\  \\boldsymbol{x})=P(\\boldsymbol{x})$与目标变量无关，进而可获得**生成式模型**对应的**贝叶斯最优分类器**：\n",
    "\n",
    "$$\n",
    "h^*(\\boldsymbol{x}) = \\underset{c \\in \\mathbf{Y}}{\\mathrm{argmax}} \\ P(c\\ ,\\ \\boldsymbol{x})\n",
    "$$\n",
    "\n",
    "\n",
    "其实在建模过程（训练过程）中，联合概率分布$P(y \\ ,\\ \\boldsymbol{x})$也可以表示成 \"**先验概率**乘上**拟然率**\",即\n",
    "\n",
    "$$\n",
    "P(y \\ ,\\ \\boldsymbol{x}) = P(\\boldsymbol{x} \\ | \\ y)P(y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2）贝叶斯最优分类器的由来\n",
    "\n",
    "假设我们通过某种概率模型已经知道后验概率分布$P(y \\ | \\ \\boldsymbol{x})$。 \n",
    "\n",
    "我们的终极目标自然是分类正确，但很难达到，于是退而求其次，我们希望错分损失最小。 为此，记$\\lambda_{i,j}$是将真实标记为$c_j$的样本错误分为$c_i$所产生的损失。于是我们可算出基于后验概率的、将样本分类成$c_i$的**期望损失**（又叫**条件风险**）$R(c_i \\ | \\ \\boldsymbol{x})$:\n",
    "\n",
    "$$\n",
    "R(c_i \\ | \\ \\boldsymbol{x}) = \\sum_{j=1}^N \\lambda_{i,j} P(c_j \\ | \\ \\boldsymbol{x})\n",
    "$$\n",
    "\n",
    "进而，通过某种**判定准则**（即，**预测函数**）$h:\\mathbf{X} \\rightarrow \\mathbf{Y}$可计算出预测函数$h$导致的总体风险$R(h)$：\n",
    "\n",
    "$$\n",
    "R(h) = \\mathbb{E}_{\\boldsymbol{x}} \\left[ R(h(\\boldsymbol{x}) \\ | \\ \\boldsymbol{x}) \\right]\n",
    "$$\n",
    "\n",
    "我们希望**错分损失最小**，即\n",
    "\n",
    "$$\n",
    "h^*(\\boldsymbol{x}) = \\underset{c \\in \\mathbf{Y}}{\\mathrm{argmin}} \\ R(c\\ |\\ \\boldsymbol{x})\n",
    "$$\n",
    "\n",
    "其中， $h^*$就是**一般的贝叶斯分类器**, 而$R(h^*)$就是**贝叶斯风险**， $1-R(h^*)$反映了分类器达到的最好性能。\n",
    "\n",
    "再特别一点， 如果我们仅仅希望**错分率最小**, 那么误判损失$\\lambda_{i,j}$可简化为：\n",
    "\n",
    "$$\n",
    "\\lambda_{i,j} = \\left\\{\\begin{array}\n",
    "& 0, & if \\ i=j; \\\\\n",
    "1, & otherwise\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "此时的**条件风险**也就简化为：\n",
    "\n",
    "$$\n",
    "R(c \\ | \\ \\boldsymbol{x}) = 1 - P(c \\ | \\ \\boldsymbol{x}), \\quad c \\in \\mathbf{Y}\n",
    "$$\n",
    "\n",
    "进而获得**错分率最小的贝叶斯分类器**：\n",
    "\n",
    "$$\n",
    "h^*(\\boldsymbol{x}) = \\underset{c \\in \\mathbf{Y}}{\\mathrm{argmax}} \\ P(c\\ |\\ \\boldsymbol{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3）极大拟然估计\n",
    "\n",
    "在建模过程（训练过程）中， 无论是**判别式模型**还是**生成式模型**，都要估计**先验概率**$P(y)$和**拟然率**$P( \\boldsymbol{x} | \\ y)$。\n",
    "\n",
    "**先验概率**$P(y)$好估计，一般采用频率估计就足够了。 现在问题集中到**拟然率**$P( \\boldsymbol{x} \\ | \\ y)$的估计了。 \n",
    "\n",
    "估计类条件概率（即，拟然率）的一种常用策略就是先假设具有某种特定概率分布形式（带参数$\\boldsymbol{\\theta}$）,然后训练出这个概率分布的参数$\\boldsymbol{\\theta}$估计。 于是**拟然率**可以改写成$P( \\boldsymbol{x} \\ | \\ y, \\boldsymbol{\\theta})$。\n",
    "\n",
    "如果给定一个带标签的训练集$\\left\\{\\boldsymbol{x}_i, y_i\\right\\}_1^m$，并且**假设样本间独立同分布**，于是我们可以写出这个训练集的**拟然函数**：\n",
    "\n",
    "$$\n",
    "L(\\boldsymbol{\\theta}) = \\prod_{i=1}^m P( \\boldsymbol{x}_i \\ | \\ y_i, \\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "由于连乘容易导致下溢，所以一般采用**对数拟然函数**：\n",
    "\n",
    "$$\n",
    "LL(\\boldsymbol{\\theta}) = \\sum_{i=1}^m \\ln P( \\boldsymbol{x}_i \\ | \\ y_i, \\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "于是可以根据**最大拟然估计原理**，可以获得模型参数$\\boldsymbol{\\theta}$的**最大拟然估计**$\\hat{\\boldsymbol{\\theta}}$：\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta}}{\\mathrm{argmax}} \\ LL(\\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "一旦有了**最大拟然估计**$\\hat{\\boldsymbol{\\theta}}$，原则上**拟然率条件概率分布**也就有了，再配上**先验概率**，进而原则上也就有**后验概率**或**联合概率分布**。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
